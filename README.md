
<p align="center">
    <img src="__assets__/logo.jpeg" height="150">
</p>


# RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation


<div align="center">

[![Paper](https://img.shields.io/badge/arXiv-Paper-b31b1b?logo=arxiv&logoColor=white)](https://arxiv.org/abs/2601.05241)
[![Website](https://img.shields.io/badge/Project-Website-pink?logo=googlechrome&logoColor=white)](https://robovip.github.io/RoboVIP/)

</div>

We propose RoboVIP, a multi-view inpainting-based video diffusion model with identity reference as conditions to augment robotics manipulation data in both simulation and real-world robot setup. 





ðŸ”¥ [Update](#Update)  **|** ðŸ”§ [Installation](#installation) **|**  ðŸ’» [Inference Augmentation](#evaluation) **|** ðŸ§© [Dataset Preprocessing](#dataset_curation)  **|** ðŸ”¥[Train](#training)  

<!-- ðŸ‘€ [**Visualization**](#Visualization)  -->



# <a name="Update"></a> Update ðŸ”¥ðŸ”¥ðŸ”¥
- [x] Release the paper
- [ ] Release the Video Diffusion Model weights and Inference Code
- [ ] Less GPU memory intense version (<80GB) of Bridge RLDS
- [ ] Release the preprocessing code of the dataset
- [ ] Release the training code for the Video Diffusion Model
- [ ] Release the simulation testing
- [ ] Release the training code for simulation


:star: **If you like RoboVIP, please help â­â­starâ­â­ this repo. Thanks!** :hugs:


Under Review.




<br>

# Citation ðŸ“š 
TBD




<br>

# Acknowledgment ðŸ¤— 
**RoboVIP** is built on [diffusers](https://github.com/huggingface/diffusers) and [RoboEngine](https://github.com/michaelyuancb/roboengine).
We appreciate the authors for sharing their awesome codebase.



